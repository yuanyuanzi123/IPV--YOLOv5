# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""Experimental modules."""

import math

import numpy as np
import torch
import torch.nn as nn

from utils.downloads import attempt_download

#Sumç±»å®ç°äº†å¤šä¸ªå±‚è¾“å‡ºçš„åŠ æƒå’Œæ“ä½œï¼Œæ”¯æŒä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šçš„è¾“å…¥ã€‚åœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥é€‰æ‹©æ˜¯å¦å¯ç”¨æƒé‡ã€‚å¦‚æœå¯ç”¨äº†æƒé‡ï¼Œåˆ™ä¼šå­¦ä¹ åˆ°ä¸€ç»„æƒé‡å‚æ•°ï¼Œç”¨äºå¯¹å„ä¸ªè¾“å…¥è¿›è¡ŒåŠ æƒæ±‚å’Œã€‚
# åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå¦‚æœå¯ç”¨äº†æƒé‡ï¼Œåˆ™ä¼šå¯¹æ¯ä¸ªè¾“å…¥ä¹˜ä»¥ç›¸åº”çš„æƒé‡ï¼Œç„¶åè¿›è¡Œæ±‚å’Œï¼›å¦åˆ™ï¼Œç›´æ¥å¯¹æ‰€æœ‰è¾“å…¥è¿›è¡Œæ±‚å’Œã€‚
class Sum(nn.Module):
    """Weighted sum of 2 or more layers https://arxiv.org/abs/1911.09070."""

    def __init__(self, n, weight=False):
        """Initializes a module to sum outputs of layers with number of inputs `n` and optional weighting, supporting 2+
        inputs.
        """
        super().__init__()
        self.weight = weight  # apply weights boolean
        self.iter = range(n - 1)  # iter object
        if weight:
            self.w = nn.Parameter(-torch.arange(1.0, n) / 2, requires_grad=True)  # layer weights

    def forward(self, x):
        """Processes input through a customizable weighted sum of `n` inputs, optionally applying learned weights."""
        y = x[0]  # no weight
        if self.weight:
            w = torch.sigmoid(self.w) * 2
            for i in self.iter:
                y = y + x[i + 1] * w[i]
        else:
            for i in self.iter:
                y = y + x[i + 1]
        return y

#MixConv2dç±»å®ç°äº†æ··åˆæ·±åº¦å·ç§¯ï¼ˆMixed Depth-wise Convï¼‰æ“ä½œï¼Œé€šè¿‡ç»“åˆå¤šä¸ªä¸åŒå¤§å°çš„å·ç§¯æ ¸ï¼Œä»è€Œå¢åŠ äº†ç½‘ç»œçš„å¤šæ ·æ€§å’Œè¡¨å¾èƒ½åŠ›ã€‚åœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥æŒ‡å®šè¾“å…¥é€šé“æ•° c1ã€
# è¾“å‡ºé€šé“æ•° c2ã€å·ç§¯æ ¸å¤§å° kã€æ­¥é•¿ sï¼Œä»¥åŠæ˜¯å¦é‡‡ç”¨ç›¸ç­‰é€šé“åˆ†é…ç­–ç•¥ equal_chã€‚åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå°†è¾“å…¥é€šè¿‡å¤šä¸ªæ··åˆæ·±åº¦å·ç§¯å±‚ï¼Œå¹¶åœ¨é€šé“ç»´åº¦ä¸Šè¿›è¡Œæ‹¼æ¥ï¼Œæœ€åç»è¿‡æ‰¹å½’ä¸€åŒ–å’Œæ¿€æ´»å‡½æ•°è¾“å‡ºã€‚
class MixConv2d(nn.Module):
    """Mixed Depth-wise Conv https://arxiv.org/abs/1907.09595."""

    def __init__(self, c1, c2, k=(1, 3), s=1, equal_ch=True):
        """Initializes MixConv2d with mixed depth-wise convolutional layers, taking input and output channels (c1, c2),
        kernel sizes (k), stride (s), and channel distribution strategy (equal_ch).
        """
        super().__init__()
        n = len(k)  # number of convolutions
        if equal_ch:  # equal c_ per group
            i = torch.linspace(0, n - 1e-6, c2).floor()  # c2 indices
            c_ = [(i == g).sum() for g in range(n)]  # intermediate channels
        else:  # equal weight.numel() per group
            b = [c2] + [0] * n
            a = np.eye(n + 1, n, k=-1)
            a -= np.roll(a, 1, axis=1)
            a *= np.array(k) ** 2
            a[0] = 1
            c_ = np.linalg.lstsq(a, b, rcond=None)[0].round()  # solve for equal weight indices, ax = b

        self.m = nn.ModuleList(
            [nn.Conv2d(c1, int(c_), k, s, k // 2, groups=math.gcd(c1, int(c_)), bias=False) for k, c_ in zip(k, c_)]
        )
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU()

    def forward(self, x):
        """Performs forward pass by applying SiLU activation on batch-normalized concatenated convolutional layer
        outputs.
        """
        return self.act(self.bn(torch.cat([m(x) for m in self.m], 1)))


#Ensembleç±»ç»§æ‰¿è‡ªnn.ModuleListï¼Œå®ƒè¡¨ç¤ºä¸€ä¸ªæ¨¡å‹çš„é›†åˆã€‚åœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å°†å¤šä¸ªæ¨¡å‹æ·»åŠ åˆ°é›†åˆä¸­ã€‚åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œ
# ä¼šå¯¹è¾“å…¥ x åº”ç”¨æ¯ä¸ªæ¨¡å‹ï¼Œå¹¶å°†å®ƒä»¬çš„è¾“å‡ºè¿›è¡Œæ‹¼æ¥ã€‚è¿™é‡Œçš„ forward æ–¹æ³•æ”¯æŒ augmentï¼ˆæ•°æ®å¢å¼ºï¼‰ã€profileï¼ˆæ€§èƒ½åˆ†æï¼‰å’Œ visualizeï¼ˆå¯è§†åŒ–ï¼‰å‚æ•°ã€‚
class Ensemble(nn.ModuleList):
    """Ensemble of models."""

    def __init__(self):
        """Initializes an ensemble of models to be used for aggregated predictions."""
        super().__init__()

    def forward(self, x, augment=False, profile=False, visualize=False):
        """Performs forward pass aggregating outputs from an ensemble of models.."""
        y = [module(x, augment, profile, visualize)[0] for module in self]
        # y = torch.stack(y).max(0)[0]  # max ensemble
        # y = torch.stack(y).mean(0)  # mean ensemble
        y = torch.cat(y, 1)  # nms ensemble
        return y, None  # inference, train output

#
#attempt_load å‡½æ•°ç”¨äºåŠ è½½å’Œèåˆä¸€ä¸ªæˆ–å¤šä¸ª YOLOv5 æ¨¡å‹çš„æƒé‡ã€‚
#å®ƒæ”¯æŒä»å•ä¸ªæƒé‡æ–‡ä»¶æˆ–ä¸€ä¸ªæƒé‡æ–‡ä»¶åˆ—è¡¨ä¸­åŠ è½½æ¨¡å‹ã€‚åŠ è½½æ¨¡å‹åï¼Œä¼šæ ¹æ®éœ€è¦è¿›è¡Œä¸€äº›æ¨¡å‹å…¼å®¹æ€§æ›´æ–°ï¼Œç„¶åå°†æ¨¡å‹æ·»åŠ åˆ° Ensemble ç±»çš„å®ä¾‹ä¸­ã€‚
def attempt_load(weights, device=None, inplace=True, fuse=True):
    """
    Loads and fuses an ensemble or single YOLOv5 model from weights, handling device placement and model adjustments.

    Example inputs: weights=[a,b,c] or a single model weights=[a] or weights=a.
    """
    from models.yolo import Detect, Model

    model = Ensemble()
    for w in weights if isinstance(weights, list) else [weights]:
        ckpt = torch.load(attempt_download(w), map_location="cpu")  # load
        ckpt = (ckpt.get("ema") or ckpt["model"]).to(device).float()  # FP32 model

        # Model compatibility updates
        if not hasattr(ckpt, "stride"):
            ckpt.stride = torch.tensor([32.0])
        if hasattr(ckpt, "names") and isinstance(ckpt.names, (list, tuple)):
            ckpt.names = dict(enumerate(ckpt.names))  # convert to dict

        model.append(ckpt.fuse().eval() if fuse and hasattr(ckpt, "fuse") else ckpt.eval())  # model in eval mode

    # Module updates
#æ­¤ä»£ç æ®µç”¨äºå¯¹æ¨¡å‹ä¸­çš„ç‰¹å®šæ¨¡å—è¿›è¡Œæ›´æ–°ã€‚å®ƒä¼šéå†æ¨¡å‹çš„æ‰€æœ‰æ¨¡å—ï¼Œå¦‚æœå‘ç°ç‰¹å®šç±»å‹çš„æ¨¡å—ï¼ˆå¦‚æ¿€æ´»å‡½æ•°ã€æ£€æµ‹å™¨ç­‰ï¼‰ï¼Œåˆ™ä¼šæ›´æ–°å…¶ inplace å±æ€§ã€‚æ­¤å¤–ï¼Œå¯¹äº nn.Upsample æ¨¡å—ï¼Œ
    # å®ƒè¿˜ä¼šæ·»åŠ ä¸€ä¸ª recompute_scale_factor å±æ€§ï¼Œä»¥ä¿æŒä¸ Torch 1.11.0 çš„å…¼å®¹æ€§ã€‚
    for m in model.modules():
        t = type(m)
        if t in (nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU, Detect, Model):
            m.inplace = inplace
            if t is Detect and not isinstance(m.anchor_grid, list):
                delattr(m, "anchor_grid")
                setattr(m, "anchor_grid", [torch.zeros(1)] * m.nl)
        elif t is nn.Upsample and not hasattr(m, "recompute_scale_factor"):
            m.recompute_scale_factor = None  # torch 1.11.0 compatibility

    # Return model
    if len(model) == 1:
        return model[-1]

    # Return detection ensemble
    print(f"Ensemble created with {weights}\n")
    for k in "names", "nc", "yaml":
        setattr(model, k, getattr(model[0], k))
    model.stride = model[torch.argmax(torch.tensor([m.stride.max() for m in model])).int()].stride  # max stride
    assert all(model[0].nc == m.nc for m in model), f"Models have different class counts: {[m.nc for m in model]}"
    return model
#è¿™æ®µä»£ç ç”¨äºæ ¹æ®åŠ è½½çš„æ¨¡å‹æƒé‡è¿”å›æ¨¡å‹æˆ–æ£€æµ‹é›†åˆã€‚å¦‚æœåŠ è½½çš„æƒé‡åªå¯¹åº”ä¸€ä¸ªæ¨¡å‹ï¼Œåˆ™ç›´æ¥è¿”å›è¯¥æ¨¡å‹ã€‚å¦‚æœåŠ è½½çš„æƒé‡å¯¹åº”å¤šä¸ªæ¨¡å‹ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ£€æµ‹é›†åˆå¹¶è¿”å›ã€‚
# åœ¨è¿”å›æ£€æµ‹é›†åˆä¹‹å‰ï¼Œè¿˜è¿›è¡Œäº†ä¸€äº›å±æ€§çš„è®¾ç½®ï¼ŒåŒ…æ‹¬è®¾ç½®é›†åˆçš„ namesã€nc å’Œ yaml å±æ€§ï¼Œä»¥åŠç¡®å®šé›†åˆä¸­æ¨¡å‹çš„æœ€å¤§æ­¥é•¿ï¼Œå¹¶å°†å…¶èµ‹ç»™é›†åˆçš„ stride å±æ€§ã€‚
# å¦‚æœé›†åˆä¸­çš„æ¨¡å‹æœ‰ä¸åŒçš„ç±»åˆ«æ•°é‡ï¼Œåˆ™ä¼šè§¦å‘æ–­è¨€é”™è¯¯ã€‚